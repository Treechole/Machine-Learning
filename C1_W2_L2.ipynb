{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(X_set, W_set, b):\n",
    "    return np.dot(W_set, X_set) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_errors(X_matrix, y_set, W_set, b):\n",
    "    errors = np.array([])\n",
    "\n",
    "    for index, training_example in enumerate(X_matrix):\n",
    "        target = y_set[index]\n",
    "        prediction = linear_regression_model(training_example, W_set, b)\n",
    "        errors = np.append(errors, np.subtract(prediction, target))\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(X_matrix, y_set, W_set, b):\n",
    "    m = X_matrix.shape[0]\n",
    "\n",
    "    errors = get_errors(X_matrix, y_set, W_set, b)\n",
    "    squared_errors = np.square(errors)\n",
    "    total_cost = np.sum(squared_errors)\n",
    "    normalized_cost = total_cost / (2 * m)\n",
    "\n",
    "    return normalized_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(X_matrix, y_set, W_set, b):\n",
    "    m = X_matrix.shape[0]\n",
    "\n",
    "    errors = get_errors(X_matrix, y_set, W_set, b)\n",
    "    dj_dW = errors @ X_matrix / m\n",
    "    dj_db = np.sum(errors) / m\n",
    "\n",
    "    return dj_dW, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1698. 1232.  715.]\n",
      "818708.8333333334\n"
     ]
    }
   ],
   "source": [
    "test_W = np.ones((4, ))\n",
    "test_b = 3\n",
    "\n",
    "print(get_errors(X_train, y_train, test_W, test_b))\n",
    "print(calculate_cost(X_train, y_train, test_W, test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.97542800e+06, 4.53866667e+03, 1.62566667e+03, 5.02383333e+04]), 1215.0)\n"
     ]
    }
   ],
   "source": [
    "print(calculate_gradient(X_train, y_train, test_W, test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_matrix, y_set, W_set, b, alpha):\n",
    "    n = X_matrix.shape[1]\n",
    "\n",
    "    threshold_value = 1e-02\n",
    "    threshold_array = np.full((n, ), threshold_value)\n",
    "    \n",
    "    num_iters = 0\n",
    "    iter_progress = []\n",
    "    cost_progress = []\n",
    "\n",
    "    dj_dW, dj_db = calculate_gradient(X_matrix, y_set, W_set, b)\n",
    "\n",
    "    while (threshold_array < np.abs(dj_dW)).all() or threshold_value < abs(dj_db):\n",
    "        if num_iters % 100000 == 0:\n",
    "            iter_progress.append(num_iters)\n",
    "            cost_progress.append(calculate_cost(X_matrix, y_set, W_set, b))\n",
    "            print(f\"Iteration: {num_iters}  W_set: {W_set}  b: {b}  Cost: {cost_progress[-1]}  dj_dW: {dj_dW}  dj_db: {dj_db}\")\n",
    "\n",
    "        dj_dW, dj_db = calculate_gradient(X_matrix, y_set, W_set, b)\n",
    "\n",
    "        W_set = W_set - alpha * dj_dW\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        num_iters += 1\n",
    "\n",
    "    return W_set, b, iter_progress, cost_progress, num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.15443468,  23.4629676 , -65.66840253,   1.82612959]),\n",
       " 1.239884067710518,\n",
       " [],\n",
       " 0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_W = np.array([0.15443468, 23.4629676, -65.66840253, 1.82612959])\n",
    "initial_b = 1.239884067710518\n",
    "\n",
    "learning_rate = 0.0000001\n",
    "gradient_descent(X_train, y_train, initial_W, initial_b, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01] [7.42220891e-06 1.94809402e-03 5.44821455e-03 2.87624082e-04]\n",
      "False False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "check_dj_dW = [7.42220891e-06, -1.94809402e-03, 5.44821455e-03, -2.87624082e-04]\n",
    "check_dj_db = -0.00010778756040963344\n",
    "\n",
    "threshold_value = 1e-02\n",
    "threshold_array = np.full((4, ), threshold_value)\n",
    "print(threshold_array, np.abs(check_dj_dW))\n",
    "print((threshold_array < np.abs(check_dj_dW)).all(), threshold_value < abs(check_dj_db))\n",
    "print((threshold_array < np.abs(check_dj_dW)).all() or threshold_value < abs(check_dj_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(cost_progress, iter_progress):\n",
    "    plt.plot(cost_progress, iter_progress, marker = None, color = \"r\")\n",
    "\n",
    "def mutiple_learning_curves(X_matrix, y_set, W_set, b, alpha_in, alpha_fin):\n",
    "    learning_curve = alpha_in\n",
    "    num_iters = 0\n",
    "    while learning_curve <= alpha_fin:\n",
    "        _, _, iter_progress, cost_progress, _ = gradient_descent(X_matrix, y_set, W_set, b, learning_curve)\n",
    "\n",
    "        plt.plot()\n",
    "\n",
    "        if num_iters % 2 == 0:\n",
    "            learning_curve *= 3\n",
    "        else:\n",
    "            learning_curve *= 10/3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
